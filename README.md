# Transformers-Text-Classification
Suggesting a neural network architecture for analyzing and recognizing texts, where transformers were used through a pre-trained BERT model, in addition to its integration with the LSTM layer with the Global Pooling layers, in order to reach a model capable of analyzing texts.
# Result:
## Neural Network Architecture:

![image](https://user-images.githubusercontent.com/108609519/184367055-1e1bb9c4-b5eb-446a-97f1-356ff0d90b73.png)

## Accuracy and other Metrics:
![image](https://user-images.githubusercontent.com/108609519/184367276-b61f256b-3004-498f-b38e-cdb0c3723430.png)
## Evaluate with Validation Data:
![image](https://user-images.githubusercontent.com/108609519/184367494-c14ad0a8-c546-487a-bd6d-213d86306086.png)

